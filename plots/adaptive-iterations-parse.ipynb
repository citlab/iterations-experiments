{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_experiments(results_path):\n",
    "    runre = re.compile(r'\\.run\\d\\d$')\n",
    "\n",
    "    experiments_dict = {}\n",
    "    \n",
    "    suites = os.listdir(results_path)\n",
    "    suites = filter(lambda x: os.path.isdir(os.path.join(results_path, x)), suites)\n",
    "    for suite in suites:\n",
    "        experiments = os.listdir(os.path.join(results_path, suite))\n",
    "        experiments = filter(lambda x: runre.search(x), experiments)\n",
    "        experiments = map(lambda x: x[:-6], experiments)\n",
    "        experiments = sorted(list(set(experiments)))\n",
    "        \n",
    "        experiments_dict[suite] = experiments\n",
    "    \n",
    "    return experiments_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tpchq10.cluster': ['tpchq10.flink.top004', 'tpchq10.flink.top008', 'tpchq10.flink.top012', 'tpchq10.flink.top016', 'tpchq10.flink.top020', 'tpchq10.flink.top024', 'tpchq10.flink.top028', 'tpchq10.flink.top032', 'tpchq10.flink.top036', 'tpchq10.flink.top040', 'tpchq10.flink.top044', 'tpchq10.flink.top048', 'tpchq10.flink.top052', 'tpchq10.flink.top056', 'tpchq10.flink.top060'], 'cc.cluster.webgraph-uk-2007-05.multijob': ['cc.flink.webgraph-uk-2007-05.multijob.top004', 'cc.flink.webgraph-uk-2007-05.multijob.top008', 'cc.flink.webgraph-uk-2007-05.multijob.top012', 'cc.flink.webgraph-uk-2007-05.multijob.top016', 'cc.flink.webgraph-uk-2007-05.multijob.top020', 'cc.flink.webgraph-uk-2007-05.multijob.top024', 'cc.flink.webgraph-uk-2007-05.multijob.top028'], 'kmeans.full.wally': ['kmeans.multi.4216562650points.top004', 'kmeans.multi.4216562650points.top008', 'kmeans.multi.4216562650points.top012', 'kmeans.multi.4216562650points.top016', 'kmeans.multi.4216562650points.top020', 'kmeans.multi.4216562650points.top024', 'kmeans.multi.4216562650points.top028', 'kmeans.multi.4216562650points.top032', 'kmeans.multi.4216562650points.top036', 'kmeans.multi.4216562650points.top040', 'kmeans.multi.4216562650points.top044', 'kmeans.multi.4216562650points.top048', 'kmeans.multi.4216562650points.top052', 'kmeans.multi.4216562650points.top056', 'kmeans.multi.4216562650points.top060'], '_broken cc runs': ['cc.flink.webgraph-uk-2007-05.multijob.top032', 'cc.flink.webgraph-uk-2007-05.multijob.top036', 'cc.flink.webgraph-uk-2007-05.multijob.top040', 'cc.flink.webgraph-uk-2007-05.multijob.top044', 'cc.flink.webgraph-uk-2007-05.multijob.top048', 'cc.flink.webgraph-uk-2007-05.multijob.top052', 'cc.flink.webgraph-uk-2007-05.multijob.top056', 'cc.flink.webgraph-uk-2007-05.multijob.top060']}\n"
     ]
    }
   ],
   "source": [
    "results_path = '/Users/lauritz/Desktop/ilya_benchmark_results'\n",
    "experiments = get_experiments(results_path)\n",
    "print experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_flink_memory_statistics(log_file):\n",
    "    pattern1 = re.compile(r'.*HEAP: (?P<used>\\d+?)/\\d+/\\d+ MB.*')\n",
    "    pattern2 = re.compile(r'.*Used Memory: (?P<used>\\d+?)$')\n",
    "    with open(log_file) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "        stats = []\n",
    "        for pattern in [pattern1, pattern2]:\n",
    "            matches = map(lambda line: pattern.match(line), lines)\n",
    "            matches = filter(lambda match: match is not None, matches)\n",
    "            used = map(lambda match: int(match.group('used')), matches)\n",
    "            stats.append(used)\n",
    "        return np.vstack(stats).T\n",
    "\n",
    "def get_flink_statistics(run_path):\n",
    "    flink_logs_folder = os.path.join(run_path, 'logs', 'flink', 'flink-1.0.0')\n",
    "    flink_logs = os.listdir(flink_logs_folder)\n",
    "    flink_logs = filter(lambda x: x.endswith('.log'), flink_logs)\n",
    "    \n",
    "    data = []\n",
    "    for flink_log in flink_logs:\n",
    "        log_file = os.path.join(flink_logs_folder, flink_log)\n",
    "        X = parse_flink_memory_statistics(log_file)\n",
    "        data.append(X)\n",
    "    data = np.vstack(data)\n",
    "    return np.mean(data, axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dstat_statistics(run_path):\n",
    "    dstat_logs_folder = os.path.join(run_path, 'logs', 'dstat', 'dstat-0.7.2')\n",
    "    dstat_logs = os.listdir(dstat_logs_folder)\n",
    "    \n",
    "    data = []\n",
    "    for dstat_log in dstat_logs:\n",
    "        log_file = os.path.join(dstat_logs_folder, dstat_log)\n",
    "        cols = range(1,7) + range(49,57)\n",
    "        df = pd.read_csv(log_file, skiprows=6, header=0, usecols=cols)\n",
    "        X = df.values\n",
    "        data.append(X)\n",
    "    data = np.vstack(data)\n",
    "    return np.mean(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_median_run(exp_path):\n",
    "    runtimes = []\n",
    "    for i in range(3):\n",
    "        path = '%s.run%02d' % (exp_path, i+1)\n",
    "        state = os.path.join(path, 'state.json')\n",
    "        with open(state) as f:\n",
    "            j = json.load(f)\n",
    "            if j['runExitCode'] != 0:\n",
    "                runtimes.append(np.inf)\n",
    "                #raise ValueError('A run did not finish successfully.')\n",
    "            else:\n",
    "                runtimes.append(j['runTime'])\n",
    "    run_idx = np.argmin(runtimes)\n",
    "    return '%s.run%02d' % (exp_path, run_idx+1), runtimes[run_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_suite(suite):\n",
    "    exps = experiments[suite]\n",
    "\n",
    "    # runtime usr sys idl wai hiq siq used buff cach free recv send read writ memheap memdirect\n",
    "    data = np.zeros((len(exps), 17))\n",
    "    for i, exp in enumerate(exps):\n",
    "        run_path, runtime = get_median_run(os.path.join(results_path, suite, exp))\n",
    "        D = get_dstat_statistics(run_path)\n",
    "        F = get_flink_statistics(run_path)\n",
    "\n",
    "        data[i,0] = runtime\n",
    "        data[i,1:15] = D\n",
    "        data[i,15:17] = F   \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tpchq10 = parse_suite('tpchq10.cluster')\n",
    "kmeans = parse_suite('kmeans.full.wally')\n",
    "cc = parse_suite('cc.cluster.webgraph-uk-2007-05.multijob')\n",
    "np.savez('experiments.npz', tpchq10=tpchq10, kmeans=kmeans, cc=cc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
